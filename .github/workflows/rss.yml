name: RSS to Jekyll Posts

on:
  schedule:
    - cron: "0 */6 * * *"   # runs every 6 hours
  workflow_dispatch:        # allows manual trigger

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install feedparser beautifulsoup4 pyyaml

      - name: Fetch Blogger RSS and convert to Jekyll posts
        run: |
          python - <<'EOF'
          import feedparser, os, re, datetime, yaml
          from bs4 import BeautifulSoup

          feed = feedparser.parse("https://jobscholarguide.blogspot.com/feeds/posts/default?alt=rss")
          os.makedirs("_posts", exist_ok=True)

          for entry in feed.entries:
              date = datetime.datetime(*entry.published_parsed[:6]).strftime("%Y-%m-%d")
              slug = re.sub(r'[^a-z0-9]+', '-', entry.title.lower()).strip('-')
              filename = f"_posts/{date}-{slug}.md"

              if not os.path.exists(filename):
                  raw_summary = entry.get("summary", "").strip()
                  soup = BeautifulSoup(raw_summary, "html.parser")
                  clean_text = soup.get_text(" ", strip=True)
                  words = clean_text.split()
                  summary = " ".join(words[:50]) + ("..." if len(words) > 50 else "")

                  tags = [t.term for t in entry.get("tags", [])] if "tags" in entry else []

                  image = None
                  if "media_thumbnail" in entry:
                      image = entry.media_thumbnail[0]['url']
                  elif "media_content" in entry:
                      image = entry.media_content[0]['url']

                  title = entry.title.replace('"', "'")

                  front_matter = {
                      "layout": "post",
                      "title": title,
                      "date": date,
                      "description": summary,
                      "tags": tags,
                      "canonical_url": entry.link,
                  }
                  if image:
                      front_matter["image"] = image

                  with open(filename, "w", encoding="utf-8") as f:
                      f.write("---\n")
                      yaml.dump(front_matter, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
                      f.write("---\n\n")
                      f.write(f"{summary}\n\n")
                      f.write("<!--more-->\n\n")
                      f.write(f"üëâ [Read the full article on JobScholarGuide]({entry.link})\n")
          EOF

      - name: Generate sitemap.xml
        run: |
          python - <<'EOF'
          import os, datetime, glob, re

          base_url = "https://jobscholarguide.github.io"
          urls = []

          for file in glob.glob("_posts/*.md"):
              m = re.match(r"_posts/(\d{4})-(\d{2})-(\d{2})-(.+)\.md", file)
              if not m:
                  continue
              y, mth, d, slug = m.groups()
              url = f"{base_url}/{y}/{mth}/{d}/{slug}.html"
              lastmod = datetime.datetime.fromtimestamp(os.path.getmtime(file)).isoformat()

              post_date = datetime.datetime(int(y), int(mth), int(d))
              age_days = (datetime.datetime.utcnow() - post_date).days
              if age_days <= 7:
                  priority, changefreq = "0.9", "daily"
              elif age_days <= 180:
                  priority, changefreq = "0.7", "weekly"
              else:
                  priority, changefreq = "0.5", "monthly"

              urls.append((url, lastmod, priority, changefreq))

          urls.append((f"{base_url}/", datetime.datetime.utcnow().isoformat(), "1.0", "daily"))

          with open("sitemap.xml", "w", encoding="utf-8") as f:
              f.write('<?xml version="1.0" encoding="UTF-8"?>\n')
              f.write('<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n')
              for loc, lastmod, priority, changefreq in urls:
                  f.write("  <url>\n")
                  f.write(f"    <loc>{loc}</loc>\n")
                  f.write(f"    <lastmod>{lastmod}</lastmod>\n")
                  f.write(f"    <changefreq>{changefreq}</changefreq>\n")
                  f.write(f"    <priority>{priority}</priority>\n")
                  f.write("  </url>\n")
              f.write("</urlset>\n")
          EOF

      - name: Generate robots.txt
        run: |
          echo "User-agent: *" > robots.txt
          echo "Allow: /" >> robots.txt
          echo "" >> robots.txt
          echo "Sitemap: https://jobscholarguide.github.io/sitemap.xml" >> robots.txt
          echo "Host: jobscholarguide.github.io" >> robots.txt

      - name: Ping search engines
        run: |
          ping_url() {
            local url=$1
            local name=$2
            local attempt=1
            local max_attempts=3
            local resp=0

            while [ $attempt -le $max_attempts ]; do
              echo "üì¢ Pinging $name (attempt $attempt)..."
              resp=$(curl -s -o /dev/null -w "%{http_code}" "$url")

              if [ "$resp" -eq 200 ]; then
                echo "‚úÖ $name ping successful"
                return 0
              else
                echo "‚ùå $name ping failed with status $resp"
              fi

              attempt=$((attempt+1))
              sleep 5
            done

            echo "‚ö†Ô∏è $name ping failed after $max_attempts attempts"
            return 1
          }

          # Major search engines
          ping_url "http://www.google.com/ping?sitemap=https://jobscholarguide.github.io/sitemap.xml" "Google"
          ping_url "http://www.bing.com/ping?sitemap=https://jobscholarguide.github.io/sitemap.xml" "Bing"
          ping_url "http://webmaster.yandex.com/ping?sitemap=https://jobscholarguide.github.io/sitemap.xml" "Yandex"
          ping_url "https://search.seznam.cz/indexnow?url=https://jobscholarguide.github.io/sitemap.xml" "Seznam"
          ping_url "https://duckduckgo.com/indexnow?url=https://jobscholarguide.github.io/sitemap.xml" "DuckDuckGo (IndexNow)"

          # Aggregator
          curl -s -o /dev/null -w "%{http_code}" -X POST "https://pingomatic.com/ping/" \
            --data "sitemap=https://jobscholarguide.github.io/sitemap.xml"
          echo "üì¢ Pingomatic notified"

      - name: Commit and push
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          git add _posts robots.txt sitemap.xml
          git commit -m "Update posts + regenerate sitemap/robots + notify search engines" || echo "No changes"
          git push
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
